# Benchmark Results: Original vs. Enhanced System

## Colab Original Code Results

### Dataset: MIMII Pump Sound Dataset
- **Source**: kagglehub (senaca/mimii-pump-sound-dataset)
- **Size**: 948 MB
- **Files**: 381 normal, 138 abnormal
- **Segments**: 5190 (3810 normal, 1380 abnormal)
- **Features**: 73 per segment

### Preprocessing
- **Sample Rate**: 16000 Hz
- **Segment Length**: 1 second
- **PCA**: 42 components (95.13% variance)
- **SMOTE**: 4152 â†’ 6096 samples
- **Train/Test**: 4152 / 1038 samples

### Model Performance on Test Set

| Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|----------|-----------|--------|----------|---------|
| **Random Forest** | 0.9432 | 0.9064 | 0.8768 | 0.8913 | 0.9807 |
| **XGBoost** | **0.9750** | **0.9664** | **0.9384** | **0.9522** | **0.9896** |
| **Autoencoder** | 0.7832 | 0.9811 | 0.1884 | 0.3161 | 0.8605 |

#### XGBoost (Best Model)
- **Confusion Matrix**:
  - TN: 753, FP: 9
  - FN: 17, TP: 259
- **Best Parameters**:
  - colsample_bytree: 0.8
  - learning_rate: 0.3
  - max_depth: 5
  - n_estimators: 200
  - subsample: 1.0
- **CV F1-Score**: 0.9863

#### Random Forest
- **Confusion Matrix**:
  - TN: 737, FP: 25
  - FN: 34, TP: 242
- **Best Parameters**:
  - class_weight: balanced
  - max_depth: None
  - min_samples_leaf: 1
  - min_samples_split: 5
  - n_estimators: 300
- **CV F1-Score**: 0.9699

#### Autoencoder
- **Confusion Matrix**:
  - TN: 761, FP: 1
  - FN: 224, TP: 52
- **Training Loss**: 0.4151
- **Characteristics**: Very high precision (98%), but low recall (19%)
  - Good for minimal false positives
  - Not ideal for complete anomaly detection

### Ablation Study - Feature Importance

| Removed Group | Number of Features | F1-Score | Performance Drop |
|---------------|-------------------|----------|------------------|
| **Time Domain** | 62 | 0.8393 | **+0.0520** |
| Spectral | 12 | 0.9151 | -0.0238 |
| MFCCs | 40 | 0.9199 | -0.0286 |
| FFT Frequency | 9 | 0.9208 | -0.0295 |
| Chroma | 2 | 0.9231 | -0.0317 |

**Interpretation**: 
- **Time domain features** are most important (largest performance drop when removed)
- Other feature groups improve performance marginally
- Ensemble of all features brings best results

## Comparison: Original Code vs. Your Enhanced System

### Architecture

| Aspect | Original Code | Your System |
|--------|---------------|-------------|
| **Structure** | Monolithic (~900 lines) | Modular (5+ modules) |
| **Code Organization** | Script-based | OOP-based |
| **Reusability** | Low | High |
| **Testability** | Difficult | Easy (Unit tests) |
| **Maintainability** | Complex | Easy |
| **Extensibility** | Laborious | Straightforward |

### Features (Identical)

Both systems implement the same 70+ features:

âœ… **Time Domain** (11 features)
- RMS, Energy, ZCR (mean/std), Mean, Std, Skewness, Kurtosis, Peak

âœ… **Frequency Domain - FFT** (9 features)
- Dominant frequency, Magnitude, Spectral Centroid/Spread, 5 band energies

âœ… **Spectral Features** (12 features)
- Spectral Centroid, Rolloff, Flatness, Bandwidth, Contrast (7 bands), Chroma

âœ… **MFCCs** (40 features)
- 20 coefficients with mean and std

âœ… **Mel-Spectrogram** (2 features)
- Overall mean and std

### ML Pipeline (Identical)

Both systems use:

âœ… **Preprocessing**
- StandardScaler for normalization
- PCA for dimensionality reduction (95% variance)
- SMOTE for class balancing

âœ… **Models**
- Random Forest with GridSearchCV
- XGBoost with GridSearchCV
- Autoencoder (TensorFlow/Keras)

âœ… **Evaluation**
- 5-Fold Stratified Cross-Validation
- Metrics: Accuracy, Precision, Recall, F1, AUC-ROC
- Confusion Matrices
- ROC Curves

### Advantages of Your System

#### 1. **Modularity**
```python
# Your system - clear separation
from audio_anom import (
    AudioFeatureExtractor,      # features.py
    RandomForestAnomalyDetector, # models_advanced.py
    ModelEvaluator              # evaluation.py
)
```

#### 2. **Reusability**
```python
# Components can be used individually
extractor = AudioFeatureExtractor(sr=16000, n_mfcc=20)
features = extractor.extract_features(audio, enhanced=True)

# Different detectors are interchangeable
detector = RandomForestAnomalyDetector()
# or
detector = XGBoostAnomalyDetector()
```

#### 3. **Testability**
```python
# Unit tests possible
def test_feature_extraction():
    extractor = AudioFeatureExtractor()
    audio = np.random.randn(16000)
    features = extractor.extract_features(audio)
    assert len(features) > 70
```

#### 4. **Configurability**
```bash
# Flexible Command-Line Interface
python src/audio_anom/train_enhanced.py \
    --models rf xgb \
    --n-mfcc 20 \
    --pca-variance 0.95 \
    --use-smote
```

#### 5. **Documentation**
- Docstrings for all functions/classes
- Type hints
- README with examples
- Separate documentation (ENHANCEMENTS.md, DATASET.md)

#### 6. **Demo Capability**
```bash
# Works without dataset
python examples/demo_enhanced.py  
# â†’ Generates synthetic data automatically
```

## Expected Performance

With the same dataset (MIMII Pump) you should achieve **identical or very similar results**:

### Expected Metrics (Your System)

| Model | Accuracy | F1-Score | AUC-ROC |
|-------|----------|----------|---------|
| Random Forest | ~0.94 | ~0.89 | ~0.98 |
| **XGBoost** | **~0.97** | **~0.95** | **~0.99** |
| Autoencoder | ~0.78 | ~0.32 | ~0.86 |

**Why identical?**
- âœ… Same feature extraction
- âœ… Same algorithms
- âœ… Same hyperparameter search
- âœ… Same preprocessing pipeline

**Possible deviations:**
- Â±1-2% due to different random seeds
- Differences in train/test split
- Hardware-dependent numerical differences

## Best Practices for Your Implementation

### 1. Dataset Download
```python
# Add to train_enhanced.py
try:
    import kagglehub
    if not os.path.exists(args.data_dir):
        print("Downloading dataset...")
        path = kagglehub.dataset_download("senaca/mimii-pump-sound-dataset")
        # Move files to args.data_dir
except Exception as e:
    print(f"Dataset download failed: {e}")
```

### 2. Reproducibility
```python
# Set all random seeds
np.random.seed(42)
tf.random.set_seed(42)
os.environ['PYTHONHASHSEED'] = '42'
```

### 3. Logging
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.info(f"Training {model_name}...")
```

### 4. Checkpoint Saving
```python
# Save intermediate results
checkpoint_dir = os.path.join(args.output_dir, 'checkpoints')
os.makedirs(checkpoint_dir, exist_ok=True)
```

## Summary

### âœ… What You Achieved:

1. **Same functionality** as original code
2. **Better code quality** (OOP, Modular, Documented)
3. **Easier maintenance** and extension
4. **Professional structure** for production deployment
5. **Testable components** for CI/CD
6. **Flexible configuration** for various use cases

### ðŸŽ¯ Next Steps:

1. **Download dataset** and test with your system
2. **Compare results** with Colab benchmark
3. **Optimize hyperparameters** for best performance
4. **Set up CI/CD pipeline**
5. **Create Docker container** for deployment
6. **Develop API endpoint** for production

### ðŸ“Š Expected Final Result:

With the MIMII Pump dataset, your system should identify **XGBoost with F1-Score ~0.95** as the best model and achieve comparable metrics to the original code - but with the advantage of a maintainable, professional codebase!

---

*Benchmark conducted on: January 15, 2026*  
*Original code dataset: MIMII Pump Sound Dataset (948 MB)*  
*Best performance: XGBoost with 97.5% Accuracy, 95.2% F1-Score*
